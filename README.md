# CCKS-2020-Product-Entity-Query-Top2

赛题链接
[CCKS 2020：基于标题的大规模商品实体检索](https://biendata.xyz/competition/ccks_2020_6/)


## 团队成员
- [Suncicie](https://github.com/Suncicie)
- [Campsa](https://github.com/jinchenyu)

### CCKS2020基于标题的大规模商品实体检索 Top2 喵喵喵队 方案说明

#### 一. 数据与任务

**1. 任务**

本题的任务是对于给定的一个商品标题，需要匹配到该标题在给定商品库中的对应商品实体。

**2. 商品标题**

商品标题猜测来自于闲鱼等UGC标题，非常不规范和含蓄，且商品标题非常短，无上下文语境，存在指代不明，别名，以及为了规避风控等的倒序等各种情况， 如下：

```
大通辣椒风湿膏8贴盒
澳洲代购 
甩卖婴儿滴剂
2006年阿胶未拆封
鹿液服 
日本久光膏药7贴/包*1包 日本带回来的久光膏药好用
焦虑、抑郁有用
```

**3. 实体库**

商品知识库包括来自淘宝网站的约**27.7w**个商品实体，主要是药品**4.4k**个和书籍类**27.3w**个，

```
{'type': 'Medical',
 'subject_id': 51730,
 'subject': '盾叶冠心宁片',
 'data': [{'predicate': '生产企业', 'object': '江苏黄河药业股份有限公司'},
  {'predicate': '主要成分', 'object': '盾叶薯蓣的根茎提取物。'},
  {'predicate': '症状',
   'object': '活血化瘀，行气止痛、养血安神。用于治疗胸痹、心痛属气滞血瘀症、高脂血症以及冠心病、心绞痛见上述证候者。对胸闷、心悸、头晕、失眠等症有改善作用。'},
  {'predicate': '规格', 'object': '铝塑板装，2×12片/板/盒。'},
  {'predicate': '产地', 'object': '中国'}]}
  
  
  {'type': 'Publication',
 'subject_id': 169274,
 'subject': '地球哼著降b調',
 'data': [{'predicate': '出版社', 'object': '河北科学技术出版社'},
  {'predicate': '作者', 'object': '袁飞 编著'},
  {'predicate': '出版时间', 'object': '2014-07'},
  {'predicate': '卷数', 'object': None},
  {'predicate': '装帧', 'object': '平装'}]}
  
  
```

**4.数据分析**

训练集共**8.3w**条数据，出现实体**1.54k**，有明显**长尾分布**趋势（如下图），

![类别统计](/Users/suncicie/Desktop/类别统计.png)

训练集中存在非常多**噪音**，如完全无意义商品标题, 以及同样商品标题但是对应不同的实体：

```
钙                                        
宝宝用品                                     
1                                         
618回血                                     
闲置物品                                      
阿胶                                         
胃药          
```

| **text_id** | **subject_id** | **text_word** | **subject**                |
| ----------- | -------------- | ------------- | -------------------------- |
| 3856        | 140183         | 药品          | 正大素克克洛己新干混悬剂   |
| 6113        | 105526         | 药品          | 肿节风软胶囊               |
| 7505        | 3880           | 药品          | 硝酸异山梨酯片(消心痛片)   |
| 7813        | 67955          | 药品          | 乌美溴铵维兰特罗吸入粉雾剂 |
| 8053        | 10286          | 药品          | 童康片                     |
| 8644        | 96414          | 药品          | 伊布替尼胶囊               |
| 11290       | 119453         | 药品          | 艾司唑仑片                 |
| 11402       | 85397          | 药品          | 脑心通胶囊                 |

#### 二. 难点与方案

主要采用pipline方式，先在27w实体库中进行粗召，再对结果进行精排，最后对难样本小样本等进行全召回的精排。 粗召在尝试bm25，规则，dssm，query-query等方式后选择过滤了小类别的多分类召回，精排则对bert-family的各个模型进行的测试。在B榜中未对样本进行清洗，只针对text文本进行了常规清洗。

#### **方案**

##### **1.丢掉小样本做多分类召回**

选取训练集中subject出现次数大于n的样本作为训练集，如当n=1时，相当于丢弃只出现一次的样本，这样在丢弃样本数不多的情况下，大大减少了多分类的类别数，提升了多分类的准确性。当作为多分类任务时，采用普通的bi-gru分类,  a榜acc可到807。 我们取这一步的预测概率最大的Top N个作为下一步精排的结果。

**2. Bert-family精排**

在上一步的多分类中，我们采用bi-gru学到了一些语义和分布信息，但丢掉了实体库中的实体详情，在这一步的精排中，我们将实体详情与text 作为pair 一起利用，实体库的数量级别与text组合那这一步的训练数据将达千万级别，因此直接采用上一步多分类TopN召回结果，将text与上一步召回的subject info 作为pair作为输入，在bert-family中，进行fine tune（b榜可达865）



|         model name         |        acc        |
| :------------------------: | :---------------: |
|        alBert-Tiny         | 0.836474438550954 |
|        Bert-wwm-ext        | 0.849226949554226 |
|         Bert-base          |  0.856562464733   |
| Roberta-wwm-ext（epoch 5） | 0.858255275928225 |
| Roberta-wwm-ext（epoch 7） | 0.865026520708724 |
|        Electra-base        |                   |
|           Xlnet            |                   |
|                            |                   |
|                            |                   |

**3. 多模型voting融合**

对Bert-family不同精排模型以及多分类模型进行voting投票，对结果进行融合，有较大提升（b榜869）

**4. 难样本全召回**

通过选取多分类结果中低置信度以及脏样本较多的的类别（阿胶），针对该类召回失败的样本，全量召回，重新使用进行bert精排中(b榜87947)

####  难点

**1. 小样本与未登录样本**

针对训练集总未出现的实体类别，考虑到这题对分布拟合的偏重，放弃考虑未登录实体。

小样本的subject在精排中被全部选入粗召集进行精排。

**2.易混淆样本**

实体库中存在大量易混淆实体，在text描述不清的情况下无法判断其正确的指向，因此在这题中，拟合分布回事这种样本的最佳选择。

```
text:维生素AD滴剂
subject:维生素AD滴剂（胶囊型）
subject:维生素AD滴剂（伊可新）

```

**3. 脏数据对分布的影响**

前期在A榜阶段对脏数据进行了一定程度的清洗，对模型acc有积极效果，后期清洗脏样本在B榜测试中失效，猜测B榜测试集经过人为筛选，导致其分布改变。

**4. 隐含表达**

前期尝试多种方法学习隐含表达来提高召回，尝试医药词典分词，别名，中英文，拼音等替换，最后发现模型有能力去学习到这类隐含表达，规则显得繁琐和低效。

##### 三. 总结与展望

因为时间和机器限制等原因，仍有一些方位未来得及尝试

1. 排序方面只尝试了Pointwise，未尝试Pairwise，Pairwise在这个场景，更专注于俩subject之间的顺序，效果会不会更好

2. electra效果不佳，训练中loss始终不降，猜测使用有问题，xlnet 训练未完成

3. 多路召回

   
